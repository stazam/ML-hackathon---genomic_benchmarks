{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction_script.ipynb",
      "provenance": [],
      "mount_file_id": "1Trj3K-jn-yWyE5e21FCCi23_nj6bBa4x",
      "authorship_tag": "ABX9TyPkyTNZvZka0n7HfKZ1YO4O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stazam/ML-hackathon---genomic_benchmarks/blob/main/Introduction_script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwdfWzo_yiyf"
      },
      "source": [
        "#pip install genomic_benchmarks --upgrade\n",
        "%%capture\n",
        "!pip install genomic_benchmarks\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, MaxPooling1D, BatchNormalization, Conv1D\n",
        "from keras import optimizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "from genomic_benchmarks.loc2seq import download_dataset\n",
        "from genomic_benchmarks.data_check import is_downloaded, info, list_datasets"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux5FmBegeffv"
      },
      "source": [
        "#Dataset - human_nontata_promoters \n",
        "\n",
        "- testovacia sada obsahuje chybajuce pozorovanie **N**, ktore sa nevyskytuje v treningovom sete, pretoho ho odstranim "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "ivw5yBAcyrLX",
        "outputId": "2722b7ef-ecd5-40f1-afb6-d1f38af2fb4b"
      },
      "source": [
        "info('human_nontata_promoters', 0)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset `human_nontata_promoters` has 2 classes: negative, positive.\n",
            "\n",
            "All lenghts of genomic intervals equals 251.\n",
            "\n",
            "Totally 36131 sequences have been found, 27097 for training and 9034 for testing.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>12355</td>\n",
              "      <td>4119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>14742</td>\n",
              "      <td>4915</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          train  test\n",
              "negative  12355  4119\n",
              "positive  14742  4915"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yFfNuoKyrPe",
        "outputId": "5444a241-b67c-4deb-cc8d-a9246ed99c6b"
      },
      "source": [
        "download_dataset(\"human_nontata_promoters\", version=0)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 1VdUg0Zu8yfLS6QesBXwGz1PIQrTW3Ze4 into /root/.genomic_benchmarks/human_nontata_promoters.zip... Done.\n",
            "Unzipping...Done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/root/.genomic_benchmarks/human_nontata_promoters')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyuXy8ZNzj4T",
        "outputId": "93eca822-698b-4e8b-e02c-d3eebdefafe1"
      },
      "source": [
        "SEQ_PATH = Path.home() / '.genomic_benchmarks' / 'human_nontata_promoters'\n",
        "CLASSES = [x.stem for x in (SEQ_PATH/'train').iterdir() if x.is_dir()]\n",
        "\n",
        "train_dset = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    SEQ_PATH / 'train',\n",
        "    batch_size=27097,\n",
        "    class_names=CLASSES)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 27097 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDE-jcqAf7qB"
      },
      "source": [
        "#tu mozno pridat PCA alebo nieco na zredukovanie dimenzie. Aj ked 251 je vpohode pre tento dataset\n",
        "\n",
        "def preprocess_notNN(dat):\n",
        "\n",
        "  dat_array = np.array(list(dat))\n",
        "\n",
        "  labels = np.array(dat_array[0][1]).astype('float32')\n",
        "  dataset = dat_array[0][0]\n",
        "\n",
        "  sequences_list = []\n",
        "  for seq in dataset:\n",
        "    if 'N' not in str(seq):\n",
        "      sequences_list.append(list(str(seq))[2:-1])\n",
        "\n",
        "  channels = {'A' : 0,'T' : 1,'C' : 2,'G' : 3}\n",
        "  \n",
        "  return np.array(pd.DataFrame(sequences_list).replace(channels)), labels"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9LCQzP0f7tU"
      },
      "source": [
        "X_train, y_train = preprocess_notNN(train_dset)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5bKbiFCh0ka",
        "outputId": "08ff93f7-804c-424c-a985-8580a98fa0de"
      },
      "source": [
        "SEQ_PATH = Path.home() / '.genomic_benchmarks' / 'human_nontata_promoters'\n",
        "CLASSES = [x.stem for x in (SEQ_PATH/'test').iterdir() if x.is_dir()]\n",
        "\n",
        "test_dset = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    SEQ_PATH / 'test',\n",
        "    batch_size=9034,\n",
        "    class_names=CLASSES) "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9034 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JLH6So2kPtO"
      },
      "source": [
        "X_test, y_test = preprocess_notNN(test_dset)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-Lkwsghk3ZN"
      },
      "source": [
        "def preprocess_NN(dat):\n",
        "\n",
        "  dat_array = np.array(list(dat))\n",
        "\n",
        "  labels = np.array(dat_array[0][1]).astype('float32')\n",
        "  dataset = dat_array[0][0]\n",
        "\n",
        "  sequences_list = []\n",
        "  for seq in dataset:\n",
        "    if not 'N' in str(seq):\n",
        "      sequences_list.append(list(str(seq))[2:-1])\n",
        "\n",
        "  samples_size = len(sequences_list)\n",
        "  sequence_size = min([len(x) for x in sequences_list])\n",
        "  ohe = np.zeros((samples_size, sequence_size, 4))\n",
        "  channels = {'A' : 0,'T' : 1,'C' : 2,'G' : 3}\n",
        "\n",
        "  for index, sequence in enumerate(sequences_list):\n",
        "    for pos, nucleotide in enumerate(sequence):\n",
        "        ohe[index, pos, channels[nucleotide]] = 1\n",
        "  \n",
        "  return ohe, labels"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_j3WZ8Qk3bB"
      },
      "source": [
        "X_train, y_train = preprocess_NN(train_dset)\n",
        "X_test, y_test = preprocess_NN(test_dset)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZDHImdXle4u"
      },
      "source": [
        "skusit ensemble s obycajnymi modeli a jednou CNN alebo potom este pridat jednu RNN a vyskusat to s nou\n",
        "\n",
        "1. samostatne modey bez NN\n",
        "2. modely s 1-nou NN - najprv CNN, potom RNN\n",
        "3. modely s 2-ma NN - CNN, RNN\n",
        "4. pouzit PCA na zredukovanie dimenzie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9yjQMc1reOK",
        "outputId": "31934b52-f805-4d86-ba86-e76a024d91d2"
      },
      "source": [
        "from google.colab import drive\n",
        "#drive.mount('/content/drive',  force_remount=True)\n",
        "drive.mount('/content/drive',  force_remount=True)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "OC2UqqcyrCob",
        "outputId": "a18a6be4-4645-47d2-8e24-3e7fe1ebafbf"
      },
      "source": [
        "#sys.path.append('/content/drive/MyDrive/CEITEC/Python_files')\n",
        "sys.path.append('/content/drive/MyDrive/Hockey_prediction/Python_script/help_functions.py')\n",
        "\n",
        "from help_functions import *"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d3490dce0d6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#sys.path.append('/content/drive/MyDrive/CEITEC/Python_files')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Hockey_prediction/Python_script/help_functions.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhelp_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'help_functions'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPQ_dRp_rdKO"
      },
      "source": [
        "stack(X_train,y_train,X_test,y_test,X_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}